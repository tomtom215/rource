name: Benchmarks

on:
  push:
    branches: [main]
  workflow_dispatch:

# Prevent concurrent benchmark runs
concurrency:
  group: benchmarks-${{ github.ref }}
  cancel-in-progress: true

# Permissions for benchmark storage
permissions:
  contents: write      # Required for gh-pages push
  deployments: write   # Required for deployment status

env:
  CARGO_TERM_COLOR: always
  RUST_BACKTRACE: 1

jobs:
  # Setup gh-pages branch if it doesn't exist (runs once)
  setup-gh-pages:
    name: Setup gh-pages Branch
    runs-on: ubuntu-latest
    if: github.event_name == 'push' && github.ref == 'refs/heads/main'
    outputs:
      branch_exists: ${{ steps.check.outputs.exists }}
    steps:
      - uses: actions/checkout@v6
        with:
          fetch-depth: 0

      - name: Check if gh-pages branch exists
        id: check
        run: |
          if git ls-remote --heads origin gh-pages | grep -q gh-pages; then
            echo "gh-pages branch already exists"
            echo "exists=true" >> $GITHUB_OUTPUT
          else
            echo "gh-pages branch does not exist, will create it"
            echo "exists=false" >> $GITHUB_OUTPUT
          fi

      - name: Create gh-pages branch
        if: steps.check.outputs.exists == 'false'
        run: |
          git config user.name "github-actions[bot]"
          git config user.email "github-actions[bot]@users.noreply.github.com"

          # Create orphan branch with initial commit
          git checkout --orphan gh-pages
          git reset --hard

          # Create initial structure
          mkdir -p dev/bench dev/sizes

          cat > README.md << 'EOF'
          # Benchmark Results

          This branch contains benchmark and size metrics for the rource project.

          ## Structure

          - `dev/bench/` - Performance benchmark data
          - `dev/sizes/` - Binary size tracking data

          ## Usage

          View the benchmark dashboard at:
          https://${{ github.repository_owner }}.github.io/${{ github.event.repository.name }}/dev/bench/

          ---
          *Auto-generated by GitHub Actions*
          EOF

          cat > dev/bench/.gitkeep << 'EOF'
          # Placeholder for benchmark data
          EOF

          cat > dev/sizes/.gitkeep << 'EOF'
          # Placeholder for size metrics
          EOF

          git add -A
          git commit -m "Initialize gh-pages branch for benchmarks and metrics"
          git push origin gh-pages

          echo "Created gh-pages branch successfully"

  benchmark:
    name: Performance Benchmarks
    runs-on: ubuntu-latest
    needs: [setup-gh-pages]
    # Run even if setup-gh-pages was skipped (for workflow_dispatch)
    if: always() && (needs.setup-gh-pages.result == 'success' || needs.setup-gh-pages.result == 'skipped')
    timeout-minutes: 30
    steps:
      - uses: actions/checkout@v6

      - uses: dtolnay/rust-toolchain@stable

      - uses: Swatinem/rust-cache@v2
        with:
          prefix-key: "v1-rust"
          shared-key: "bench"

      - name: Run benchmarks
        run: |
          # Run benchmarks, capture output cleanly
          cargo bench --workspace -- --noplot 2>&1 | tee benchmark-raw.txt

          # Create a clean summary (filter out noise, keep results)
          echo "=== Benchmark Results ===" > benchmark-results.txt
          grep -E '(^test |time:|thrpt:|Benchmarking|^[a-zA-Z_/]+\s+time:)' benchmark-raw.txt >> benchmark-results.txt 2>/dev/null || true

      - name: Extract Criterion results
        run: |
          # Convert Criterion output to JSON format for benchmark-action
          python3 << 'PYEOF'
          import json
          import re

          results = []
          with open('benchmark-raw.txt', 'r') as f:
              content = f.read()

          # Parse Criterion benchmark output
          # Format: "group/name/variant    time:   [lower bound  estimate  upper bound]"
          pattern = r'([\w/]+)\s+time:\s+\[([0-9.]+)\s+(\w+)\s+([0-9.]+)\s+(\w+)\s+([0-9.]+)\s+(\w+)\]'

          for match in re.finditer(pattern, content):
              name = match.group(1)
              value = float(match.group(4))  # Use estimate (middle value)
              unit = match.group(5)

              # Convert to nanoseconds for consistency
              multipliers = {'ns': 1, 'Âµs': 1000, 'us': 1000, 'ms': 1000000, 's': 1000000000}
              value_ns = value * multipliers.get(unit, 1)

              results.append({
                  'name': name,
                  'unit': 'ns',
                  'value': value_ns
              })

          # Write results even if empty (benchmark-action needs valid JSON)
          with open('benchmark-data.json', 'w') as f:
              json.dump(results, f, indent=2)

          print(f"Extracted {len(results)} benchmark results")

          if len(results) == 0:
              print("WARNING: No benchmark results extracted. Check benchmark output format.")
          PYEOF

      - name: Check if benchmarks were extracted
        id: check_benchmarks
        run: |
          RESULT_COUNT=$(python3 -c "import json; print(len(json.load(open('benchmark-data.json'))))")
          echo "result_count=$RESULT_COUNT" >> $GITHUB_OUTPUT
          if [ "$RESULT_COUNT" -eq 0 ]; then
            echo "::warning::No benchmark results were extracted. Skipping benchmark storage."
          else
            echo "Found $RESULT_COUNT benchmark results"
          fi

      - name: Store benchmark result
        uses: benchmark-action/github-action-benchmark@v1
        if: github.event_name == 'push' && github.ref == 'refs/heads/main' && steps.check_benchmarks.outputs.result_count != '0'
        with:
          name: Rust Benchmarks
          tool: 'customSmallerIsBetter'
          output-file-path: benchmark-data.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '110%'
          comment-on-alert: true
          fail-on-alert: false
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: dev/bench

      - name: Generate benchmark summary
        if: always()
        run: |
          echo "## Performance Benchmarks" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "**Branch:** \`${{ github.ref_name }}\`" >> $GITHUB_STEP_SUMMARY
          echo "**Commit:** \`${{ github.sha }}\`" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY

          RESULT_COUNT=$(python3 -c "import json; print(len(json.load(open('benchmark-data.json'))))" 2>/dev/null || echo "0")

          if [ "$RESULT_COUNT" -eq 0 ]; then
            echo "No benchmark results extracted." >> $GITHUB_STEP_SUMMARY
          else
            echo "### Results ($RESULT_COUNT benchmarks)" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY

            # Create a clean table from JSON
            python3 << 'PYEOF'
          import json

          with open('benchmark-data.json') as f:
              data = json.load(f)

          if data:
              print("| Benchmark | Time (ns) | Time (human) |", file=open('/tmp/bench_table.md', 'w'))
              print("|-----------|-----------|--------------|", file=open('/tmp/bench_table.md', 'a'))
              for entry in sorted(data, key=lambda x: x['name']):
                  ns = entry['value']
                  if ns >= 1_000_000:
                      human = f"{ns/1_000_000:.2f} ms"
                  elif ns >= 1_000:
                      human = f"{ns/1_000:.2f} us"
                  else:
                      human = f"{ns:.2f} ns"
                  print(f"| `{entry['name']}` | {ns:.1f} | {human} |", file=open('/tmp/bench_table.md', 'a'))
          PYEOF
            cat /tmp/bench_table.md >> $GITHUB_STEP_SUMMARY 2>/dev/null || true
          fi

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "---" >> $GITHUB_STEP_SUMMARY
          echo "*Run on-demand via workflow_dispatch to get fresh numbers.*" >> $GITHUB_STEP_SUMMARY

      - name: Upload benchmark results
        uses: actions/upload-artifact@v6
        with:
          name: benchmark-results
          path: |
            benchmark-raw.txt
            benchmark-results.txt
            benchmark-data.json

  # Size tracking - monitor binary and WASM sizes
  size-check:
    name: Size Check
    runs-on: ubuntu-latest
    needs: [setup-gh-pages]
    # Run even if setup-gh-pages was skipped
    if: always() && (needs.setup-gh-pages.result == 'success' || needs.setup-gh-pages.result == 'skipped')
    timeout-minutes: 20
    steps:
      - uses: actions/checkout@v6

      - uses: dtolnay/rust-toolchain@stable
        with:
          targets: wasm32-unknown-unknown

      - uses: Swatinem/rust-cache@v2
        with:
          prefix-key: "v1-rust"
          shared-key: "size-check"

      - name: Install wasm-pack
        uses: jetli/wasm-pack-action@v0.4.0
        with:
          version: 'latest'

      - name: Install binaryen
        run: |
          sudo apt-get update
          sudo apt-get install -y binaryen

      - name: Build release binary
        run: cargo build --release

      - name: Build optimized WASM
        run: |
          cd rource-wasm
          wasm-pack build --target web --release
          cd pkg
          # Feature flags MUST come before input file for validation
          wasm-opt \
            --enable-simd \
            --enable-bulk-memory \
            --enable-sign-ext \
            --enable-nontrapping-float-to-int \
            --enable-mutable-globals \
            -Oz \
            -o rource_wasm_bg_opt.wasm rource_wasm_bg.wasm
          mv rource_wasm_bg_opt.wasm rource_wasm_bg.wasm

      - name: Report sizes
        id: sizes
        run: |
          echo "## Binary Sizes" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "| Artifact | Size | Gzipped |" >> $GITHUB_STEP_SUMMARY
          echo "|----------|------|---------|" >> $GITHUB_STEP_SUMMARY

          # Native binary
          native_size=$(ls -lh target/release/rource | awk '{print $5}')
          native_bytes=$(stat -c%s target/release/rource)
          native_gzip=$(gzip -c target/release/rource | wc -c | numfmt --to=iec-i --suffix=B)
          echo "| Native binary | $native_size | $native_gzip |" >> $GITHUB_STEP_SUMMARY

          # WASM
          wasm_size=$(ls -lh rource-wasm/pkg/rource_wasm_bg.wasm | awk '{print $5}')
          wasm_bytes=$(stat -c%s rource-wasm/pkg/rource_wasm_bg.wasm)
          wasm_gzip_bytes=$(gzip -c rource-wasm/pkg/rource_wasm_bg.wasm | wc -c)
          wasm_gzip=$(echo $wasm_gzip_bytes | numfmt --to=iec-i --suffix=B)
          echo "| WASM bundle | $wasm_size | $wasm_gzip |" >> $GITHUB_STEP_SUMMARY

          # JS bindings
          js_size=$(ls -lh rource-wasm/pkg/rource_wasm.js | awk '{print $5}')
          echo "| JS bindings | $js_size | - |" >> $GITHUB_STEP_SUMMARY

          echo "" >> $GITHUB_STEP_SUMMARY
          echo "### Size Targets" >> $GITHUB_STEP_SUMMARY
          echo "- Native binary: < 5MB" >> $GITHUB_STEP_SUMMARY
          echo "- WASM (gzipped): < 300KB" >> $GITHUB_STEP_SUMMARY

          # Export for later steps
          echo "native_bytes=$native_bytes" >> $GITHUB_OUTPUT
          echo "wasm_bytes=$wasm_bytes" >> $GITHUB_OUTPUT
          echo "wasm_gzip_bytes=$wasm_gzip_bytes" >> $GITHUB_OUTPUT

      - name: Check size limits
        run: |
          native_bytes=${{ steps.sizes.outputs.native_bytes }}
          wasm_gzip_bytes=${{ steps.sizes.outputs.wasm_gzip_bytes }}

          # Check native binary size (< 5MB)
          if [ $native_bytes -gt 5242880 ]; then
            echo "::warning::Native binary exceeds 5MB target: $(numfmt --to=iec-i --suffix=B $native_bytes)"
          fi

          # Check WASM gzipped size (< 300KB)
          if [ $wasm_gzip_bytes -gt 307200 ]; then
            echo "::warning::WASM gzipped exceeds 300KB target: $(numfmt --to=iec-i --suffix=B $wasm_gzip_bytes)"
          fi

      - name: Create size metrics JSON
        run: |
          native_bytes=${{ steps.sizes.outputs.native_bytes }}
          wasm_bytes=${{ steps.sizes.outputs.wasm_bytes }}
          wasm_gzip_bytes=${{ steps.sizes.outputs.wasm_gzip_bytes }}

          cat > size-metrics.json << EOF
          [
            {"name": "Native Binary", "unit": "bytes", "value": $native_bytes},
            {"name": "WASM Bundle", "unit": "bytes", "value": $wasm_bytes},
            {"name": "WASM Gzipped", "unit": "bytes", "value": $wasm_gzip_bytes}
          ]
          EOF

      - name: Store size metrics
        uses: benchmark-action/github-action-benchmark@v1
        if: github.event_name == 'push' && github.ref == 'refs/heads/main'
        with:
          name: Binary Sizes
          tool: 'customSmallerIsBetter'
          output-file-path: size-metrics.json
          github-token: ${{ secrets.GITHUB_TOKEN }}
          auto-push: true
          alert-threshold: '120%'
          comment-on-alert: true
          fail-on-alert: false
          gh-pages-branch: gh-pages
          benchmark-data-dir-path: dev/sizes

      - name: Upload size metrics
        uses: actions/upload-artifact@v6
        with:
          name: size-metrics
          path: size-metrics.json

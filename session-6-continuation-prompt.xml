<session-continuation>
  <metadata>
    <session-number>6</session-number>
    <parent-session>5</parent-session>
    <branch>claude/defect-risk-metrics-4wC0P</branch>
    <project>Rource (Rust + Gource)</project>
    <standard>PEER REVIEWED PUBLISHED ACADEMIC</standard>
    <date-created>2026-02-10</date-created>
    <context>
      Session 5 completed: (1) Added 83 mutation-killing tests across 9 defect-risk
      metric modules (I11-I19), (2) Fixed CI mutation testing pipeline that was being
      killed at exactly 30 minutes due to 4 root causes: platform hard-limit overriding
      timeout-minutes, cargo install compiling from source (~15min), mutants.toml at wrong
      path, and exit-code handling bug with bash set -e. All fixes verified — CI passed.
      Branch merged. Session 6 must advance the insights engine to the next level.
    </context>
  </metadata>

  <mandatory-standards>
    <standard id="NEVER-GUESS">
      Never guess. Never assume. Never approximate. Never overstate. Never exaggerate.
      Every claim must be verifiable, auditable, precise, and honest. When uncertain,
      say "I don't know" or "This needs verification." When wrong, immediately correct.
    </standard>
    <standard id="NEVER-SKIP">
      Never skip tests. Never dismiss warnings. Never ignore errors. Never proceed with
      broken code. Never commit undocumented changes. Zero clippy warnings with
      --all-targets --all-features. Zero test failures. Zero compromises.
    </standard>
    <standard id="ALWAYS-MEASURE">
      Always benchmark BEFORE and AFTER changes. Always report exact values with units.
      "52.3% improvement (2.41us to 1.15us)" — never "~50% faster." Statistical rigor:
      criterion with 100+ samples, 95% CI, reproducible.
    </standard>
    <standard id="ALWAYS-VERIFY">
      Run cargo test, cargo clippy --all-targets --all-features -- -D warnings, and
      cargo fmt --check before every commit. Verify every file path with ls.
      Verify every code snippet against actual source. Verify every numerical claim
      against ground truth.
    </standard>
    <standard id="ALWAYS-DOCUMENT">
      Document as you implement. Every change needs before/after metrics.
      Every algorithm needs complexity analysis. Every formula needs a citation.
      Every test needs a mutation-killing justification comment.
    </standard>
    <standard id="FIX-EVERYTHING">
      If you encounter ANY issue — whether you caused it or not — you are responsible
      for fixing it. There is no "pre-existing issue." There is no "out of scope."
      You touched it, you own it. Fix it NOW.
    </standard>
    <standard id="REMARKABLE-IMPROVEMENT">
      Every session must be remarkably better than the previous session. Session 5
      established 83 mutation-killing tests and fixed a 4-bug CI pipeline. Session 6
      must exceed that bar in scope, rigor, and measurable impact.
    </standard>
  </mandatory-standards>

  <session-5-learnings>
    <learning id="L1" category="ci-cd">
      The CI platform enforces a hard 30-minute job limit that overrides timeout-minutes
      in workflow YAML. All CI jobs must be designed to complete within 30 minutes.
      This is a platform constraint, not a configuration issue.
    </learning>
    <learning id="L2" category="ci-cd">
      cargo-mutants config file must be at .cargo/mutants.toml, NOT at workspace root.
      cargo-mutants follows Cargo's convention for config location. Misplacing it causes
      exclude_re patterns to be silently ignored.
    </learning>
    <learning id="L3" category="ci-cd">
      Use cargo binstall instead of cargo install --locked in CI. Pre-built binary
      download takes ~30 seconds vs ~15 minutes for source compilation. This recovered
      14.5 minutes of the 30-minute CI budget.
    </learning>
    <learning id="L4" category="ci-cd">
      GitHub Actions default shell is bash -eo pipefail. Never put EXIT_CODE=$? on a
      standalone line after a command that may fail — set -e kills the script before
      reaching the assignment. Use EXIT_CODE=0; cmd || EXIT_CODE=$? pattern.
    </learning>
    <learning id="L5" category="ci-cd">
      cancel-in-progress: false prevents concurrent-push cancellation but does NOT
      prevent platform-level timeout kills. These are independent mechanisms.
    </learning>
    <learning id="L6" category="mutation-testing">
      Equivalent mutants must be proven equivalent with mathematical argument, not
      assumed. Document the proof in .cargo/mutants.toml comments and in test files.
      4 proven equivalent mutants documented in Session 5.
    </learning>
    <learning id="L7" category="mutation-testing">
      exclude_re in .cargo/mutants.toml uses Rust regex crate syntax, matched against
      the full mutant description string including file path, line context, and
      mutation description.
    </learning>
    <learning id="L8" category="testing">
      Mutation-killing tests must use exact value assertions (assert!((result - expected).abs() &lt; 1e-10))
      not range assertions (assert!(result > 0.0)). Range assertions cannot kill
      arithmetic operator mutations.
    </learning>
    <learning id="L9" category="testing">
      Each mutation-killing test must have a comment documenting which specific mutation
      it kills: // Kills: replace / with * in avg_burst_length calculation
    </learning>
    <learning id="L10" category="architecture">
      The insights engine uses a single-pass O(N) accumulation architecture with 17
      accumulators. All computation happens at load time, not per-frame. Zero impact
      on the 20us frame budget.
    </learning>
  </session-5-learnings>

  <current-state>
    <insights-engine>
      <total-modules>20</total-modules>
      <total-tests>352</total-tests>
      <equivalent-mutants-documented>4</equivalent-mutants-documented>
      <architecture>Single-pass O(N) accumulation with 17 accumulators, parallel finalization</architecture>
      <bulk-commit-threshold>50 files (excluded from coupling analysis)</bulk-commit-threshold>
    </insights-engine>

    <module-status>
      <module name="change_bursts" tests="23" mutation-tests="yes" status="HARDENED" paper="Nagappan 2010">
        Per-file rapid-change detection. 48h gap threshold, min burst length 3.
        Risk = burst_count * log2(1 + max_burst_length) * (1 + multi_author_factor).
      </module>
      <module name="change_entropy" tests="21" mutation-tests="yes" status="HARDENED" paper="Hassan 2009">
        Sliding 30-day window Shannon entropy. H(W) = -sum(p(f) * log2(p(f))).
        Normalized by log2(files_modified). Trend: first-half vs second-half avg (threshold 0.05).
      </module>
      <module name="circadian" tests="15" mutation-tests="yes" status="HARDENED" paper="Eyolfson 2011">
        UTC hour risk weights: 00-03=1.0, 04-06=0.7, 07-11=0.2, 12-17=0.4, 18-23=0.6.
        Weekend multiplier 1.3. High-risk percentage = commits in 00:00-03:59 / total.
      </module>
      <module name="inequality" tests="19" mutation-tests="yes" status="HARDENED" paper="Chelkowski 2016">
        Gini coefficient from sorted commit counts. Gini = (2*sum(i*c_i))/(n*sum(c)) - (n+1)/n.
        Lorenz curve (20 points). Sliding 90-day windowed Gini.
      </module>
      <module name="focus" tests="21" mutation-tests="yes" status="HARDENED" paper="Posnett 2013">
        Developer focus = 1.0 - H_norm(directory_distribution).
        File diffusion = H(contributor_distribution) / log2(num_contributors).
        Directory extraction: first path component before '/'.
      </module>
      <module name="survival" tests="16" mutation-tests="yes" status="HARDENED" paper="Cito 2021">
        Kaplan-Meier survival curve. S(t_i) = S(t_{i-1}) * (n_i - d_i) / n_i.
        Infant mortality threshold: 30 days. Median: first t where S(t) &lt; 0.5.
      </module>
      <module name="modularity" tests="15" mutation-tests="yes" status="HARDENED" paper="Silva 2014">
        Co-change modularity index = 1.0 - (cross_module_edges / total_edges).
        Per-directory score = internal / (internal + external). Sorted ascending.
      </module>
      <module name="congruence" tests="16" mutation-tests="yes" status="HARDENED" paper="Cataldo 2008">
        Sociotechnical congruence = |CR intersect AC| / |CR|.
        CR: required coordination pairs from coupling. AC: actual coordination from shared files.
        Top 20 coordination gaps. Pair normalization: lexicographic ordering.
      </module>
      <module name="network" tests="27" mutation-tests="yes" status="HARDENED" paper="Begel 2023">
        Developer collaboration graph. Density = 2E / (V(V-1)). Avg degree = 2E / V.
        Clustering coefficient (Watts-Strogatz). Brandes betweenness (3 &lt;= V &lt;= 100).
        Connected components via BFS. Undirected edges (divided by 2).
      </module>
      <module name="cadence" tests="17" mutation-tests="1" status="NEEDS-HARDENING" paper="Eyolfson 2014">
        Gap: CV classification thresholds (0.5, 1.5) not boundary-tested.
        Gap: Median calculation and std_dev formula vulnerable to off-by-one mutations.
        Gap: Only 1 explicit mutation-killing test (division).
      </module>
      <module name="coupling" tests="10" mutation-tests="2" status="NEEDS-HARDENING" paper="D'Ambros 2009">
        Gap: Confidence formula (support / total_changes) only tested with 2 pairs.
        Gap: Asymmetric file change counts (3 vs 100 changes) not tested.
        Gap: Only 10 tests total — lowest count of any module.
      </module>
      <module name="growth" tests="17" mutation-tests="2" status="NEEDS-HARDENING" paper="Lehman 1996">
        Gap: Trend classification ratio threshold (>1.2) has zero boundary tests.
        Gap: Active file set tracking not validated with complex create/delete sequences.
        Gap: Accelerating/decelerating/stable edge cases missing.
      </module>
      <module name="hotspot" tests="9" mutation-tests="3" status="HARDENED" paper="Nagappan 2005">
        Exponential decay weighting. Score = weighted_changes * (1 + ln_1p(total)).
        Decay formula, boundary tests, and direction tests present.
      </module>
      <module name="knowledge" tests="15" mutation-tests="4" status="NEEDS-HARDENING" paper="Rigby 2013">
        Gap: Entropy formula only tested with &lt;= 3 contributors.
        Gap: Asymmetric distributions (e.g., 90/10 split) not tested.
        Gap: Need 5+ contributor scenarios for formula validation.
      </module>
      <module name="lifecycle" tests="20" mutation-tests="6" status="PARTIALLY-HARDENED" paper="Godfrey 2000">
        Good boundary tests (exactly 30 days, exact thresholds).
        Gap: Churn rate with complex mixed create/delete patterns.
        Gap: Zero-age and very-old-file edge cases for modifications_per_month.
      </module>
      <module name="ownership" tests="15" mutation-tests="2" status="NEEDS-HARDENING" paper="Bird 2011">
        Gap: Bus factor greedy set cover algorithm only 3 test scenarios.
        Gap: Need 5-10 tests covering overlapping ownership, disjoint ownership, power-law.
        Gap: Tie-breaking behavior in set cover algorithm not validated.
      </module>
      <module name="profiles" tests="19" mutation-tests="7" status="HARDENED" paper="Mockus 2002">
        Drive-by boundary (&lt;= 2), core share (&gt;= 10%), recency thresholds well-tested.
        7 explicit mutation-killing tests. Classification boundaries validated.
      </module>
      <module name="temporal" tests="17" mutation-tests="2" status="NEEDS-HARDENING" paper="Eyolfson 2011">
        Gap: Burst merging algorithm only 1 test case.
        Gap: Adjacent burst, overlapping burst, and boundary-slide edge cases missing.
        Gap: Window slide correctness with complex overlapping scenarios.
      </module>
      <module name="work_type" tests="21" mutation-tests="7" status="HARDENED" paper="Hindle 2008">
        All three thresholds (0.3, 0.5, 0.7) boundary-tested with exact and just-above.
        Priority/tie-breaking tests. 7 explicit mutation-killing tests. Best coverage.
      </module>
    </module-status>

    <ci-pipeline>
      <mutation-workflow>Fixed in Session 5. Uses cargo-binstall (~30s), 20m time budget,
        EXIT_CODE=0 pattern, 30m timeout-minutes matching platform limit.</mutation-workflow>
      <equivalent-mutants>4 documented in .cargo/mutants.toml:
        1. change_bursts.rs: > 1 vs >= 1 (boundary yields 0.0 either way)
        2. change_entropy.rs: || vs &amp;&amp; (early return optimization, same output)
        3. change_entropy.rs: &lt; vs &lt;= (extra zero-length window filtered)
        4. change_entropy.rs: > 0.0 vs >= 0.0 (p always > 0 from integer counts)
      </equivalent-mutants>
    </ci-pipeline>
  </current-state>

  <task-specification>
    <title>Insights Engine: Mutation Hardening Phase 2 + Integration + Documentation</title>
    <priority>CRITICAL</priority>

    <phase id="1" name="Verify Clean Baseline">
      <description>
        Before ANY implementation work begins, verify the codebase is clean and
        establish ground-truth baselines. This is non-negotiable.
      </description>
      <steps>
        <step>Run: cargo test (all tests must pass)</step>
        <step>Run: cargo clippy --all-targets --all-features -- -D warnings (zero warnings)</step>
        <step>Run: cargo fmt --check (must be formatted)</step>
        <step>Run: cargo test -p rource-core insights -- --list 2>&amp;1 | wc -l (record exact test count — expect ~352)</step>
        <step>Run: cargo tarpaulin -p rource-core --engine Llvm --out Stdout 2>&amp;1 | grep "coverage" (record coverage baseline)</step>
        <step>Verify branch: git branch --show-current (must be claude/defect-risk-metrics-4wC0P or create it from main)</step>
        <step>Record all baseline numbers — you will need them for before/after reporting</step>
      </steps>
    </phase>

    <phase id="2" name="Mutation-Killing Test Hardening: 7 Remaining Modules">
      <description>
        Add targeted mutation-killing tests to the 7 modules identified as NEEDS-HARDENING.
        Each test must have a // Kills: comment documenting the specific mutation it defeats.
        Use exact value assertions (1e-10 tolerance), not range checks.
        Target: 5-10 new tests per module, ~40-60 new tests total.
      </description>

      <module name="cadence.rs" priority="MEDIUM" new-tests-target="5-8">
        <gap>CV classification thresholds (0.5 and 1.5) not boundary-tested</gap>
        <gap>Median calculation vulnerable to off-by-one</gap>
        <gap>std_dev formula operator mutations unkilled</gap>
        <tests-needed>
          - test_cv_boundary_exactly_0_5 (regular vs erratic boundary)
          - test_cv_boundary_exactly_1_5 (erratic vs chaotic boundary)
          - test_cv_just_below_0_5 and test_cv_just_above_0_5
          - test_median_interval_odd_count (middle element selection)
          - test_median_interval_even_count (average of two middle elements, if applicable)
          - test_std_dev_formula_exact (kills sqrt, division, subtraction mutations)
          - test_team_mean_weighted_exact (formula verification with known inputs)
        </tests-needed>
      </module>

      <module name="coupling.rs" priority="HIGH" new-tests-target="8-10">
        <gap>Confidence formula only tested with 2 pairs</gap>
        <gap>Asymmetric file change counts not tested</gap>
        <gap>Lowest test count of any module (10)</gap>
        <tests-needed>
          - test_confidence_asymmetric_counts (file A: 100 changes, file B: 3 changes)
          - test_confidence_boundary_at_one (100% confidence when always co-changed)
          - test_confidence_division_exact (kills / vs * in confidence = support / total)
          - test_bulk_commit_threshold_excluded (commits with >50 files skipped)
          - test_bulk_commit_threshold_boundary_50 (exactly 50 files: included or excluded?)
          - test_coupling_pair_ordering (verify deterministic ordering)
          - test_support_count_increment (kills += 1 vs += 0 or -= 1)
          - test_three_file_commit_generates_three_pairs (combinatorial correctness)
          - test_single_file_commit_no_coupling (no pairs generated)
          - test_confidence_zero_when_no_co_change (A changed alone, never with B)
        </tests-needed>
      </module>

      <module name="growth.rs" priority="MEDIUM" new-tests-target="5-7">
        <gap>Trend classification ratio threshold (>1.2) has zero boundary tests</gap>
        <gap>Active file set tracking not validated with complex sequences</gap>
        <tests-needed>
          - test_trend_ratio_exactly_1_2 (boundary: stable or accelerating?)
          - test_trend_ratio_just_below_1_2 (1.19 → stable)
          - test_trend_ratio_just_above_1_2 (1.21 → accelerating)
          - test_decelerating_trend_ratio_below_0_8 (verify threshold)
          - test_active_files_create_then_delete (net growth = 0)
          - test_net_growth_subtraction_kills_addition (exact arithmetic)
          - test_avg_monthly_growth_division_exact (known months, known count)
        </tests-needed>
      </module>

      <module name="knowledge.rs" priority="MEDIUM" new-tests-target="5-7">
        <gap>Entropy formula only tested with &lt;= 3 contributors</gap>
        <gap>Asymmetric distributions (90/10) not tested</gap>
        <tests-needed>
          - test_entropy_five_equal_contributors (H = log2(5) = 2.3219...)
          - test_entropy_asymmetric_90_10_split (exact expected value)
          - test_entropy_single_contributor_is_zero (H = 0 when p = 1.0)
          - test_silo_detection_boundary (1 contributor = silo, 2 = not)
          - test_directory_entropy_aggregation_exact (multi-dir scenario)
          - test_knowledge_distribution_with_power_law (realistic scenario)
        </tests-needed>
      </module>

      <module name="ownership.rs" priority="HIGH" new-tests-target="8-10">
        <gap>Bus factor greedy set cover algorithm only 3 test scenarios</gap>
        <gap>Tie-breaking behavior in set cover not validated</gap>
        <tests-needed>
          - test_bus_factor_five_files_three_owners (non-trivial set cover)
          - test_bus_factor_disjoint_ownership (each file by different owner)
          - test_bus_factor_power_law_distribution (1 dev owns 80% of files)
          - test_bus_factor_overlapping_ownership (multiple devs share files)
          - test_bus_factor_single_owner_all_files (bus factor = 1)
          - test_ownership_share_exact_with_three_devs (verify division formula)
          - test_top_owner_is_majority_contributor (sorted by share descending)
          - test_bus_factor_tie_breaking (equal coverage → deterministic choice)
          - test_bus_factor_with_many_files (10+ files, verify set cover correctness)
        </tests-needed>
      </module>

      <module name="temporal.rs" priority="HIGH" new-tests-target="6-8">
        <gap>Burst merging algorithm only 1 test case</gap>
        <gap>Adjacent and overlapping burst scenarios missing</gap>
        <tests-needed>
          - test_burst_merge_adjacent_within_window (two bursts, gap &lt; BURST_WINDOW_SECONDS)
          - test_burst_no_merge_gap_exceeds_window (two bursts, gap > BURST_WINDOW_SECONDS)
          - test_burst_merge_boundary_exact (gap == BURST_WINDOW_SECONDS exactly)
          - test_burst_threshold_exactly_10_commits (10 commits in window = burst)
          - test_burst_threshold_9_commits_no_burst (9 commits = not a burst)
          - test_burst_file_count_division_exact (avg files per burst calculation)
          - test_commits_per_day_division_exact (total / days calculation)
          - test_peak_hour_and_day_detection (verify argmax correctness)
        </tests-needed>
      </module>

      <module name="lifecycle.rs" priority="LOW" new-tests-target="3-5">
        <gap>Churn rate with complex mixed patterns</gap>
        <gap>Zero-age edge case for modifications_per_month</gap>
        <tests-needed>
          - test_modifications_per_month_zero_age (file created and only commit = 0 age)
          - test_churn_rate_mixed_create_modify_delete (realistic sequence)
          - test_stage_transition_boundary_active_to_stable (exact threshold)
        </tests-needed>
      </module>
    </phase>

    <phase id="3" name="Run CI Mutation Testing and Validate">
      <description>
        After adding mutation-killing tests, push and verify the CI mutation testing
        pipeline passes. The pipeline was fixed in Session 5 — this validates both
        the test improvements and the CI fixes working together.
      </description>
      <steps>
        <step>Commit all new tests with descriptive message including test counts</step>
        <step>Push to branch claude/defect-risk-metrics-4wC0P</step>
        <step>Monitor CI — mutation jobs should complete within 30 minutes</step>
        <step>If any MISSED mutants remain, analyze whether they are:
          (a) equivalent mutants needing .cargo/mutants.toml exclusion with proof, or
          (b) genuine gaps needing additional tests</step>
        <step>For any new equivalent mutants: document the proof of equivalence,
          add exclude_re pattern to .cargo/mutants.toml</step>
        <step>Target: 80%+ mutation score for rource-core insights module</step>
      </steps>
    </phase>

    <phase id="4" name="Integration Testing">
      <description>
        Create end-to-end integration tests that validate the full insights pipeline
        from CommitRecord input through InsightsReport output. Current tests are
        per-module unit tests; integration tests verify cross-module correctness.
      </description>
      <tests-needed>
        - test_full_pipeline_single_commit (verify all 20 metrics computed)
        - test_full_pipeline_empty_commits (all metrics handle empty input gracefully)
        - test_full_pipeline_100_commits (realistic synthetic repository)
        - test_full_pipeline_single_author (ownership, bus factor, network degenerate cases)
        - test_full_pipeline_single_file (coupling, modularity degenerate cases)
        - test_accumulator_single_pass_invariant (verify N commits processed in exactly N iterations)
        - test_bulk_commit_threshold_respected (commits with >50 files excluded from coupling)
        - test_deterministic_output (same input twice produces identical InsightsReport)
      </tests-needed>
    </phase>

    <phase id="5" name="Property-Based Testing for Mathematical Invariants">
      <description>
        Add property-based tests (using proptest or quickcheck) to verify mathematical
        invariants that must hold for ALL inputs, not just hand-crafted test cases.
        These are critical for PEER REVIEWED PUBLISHED ACADEMIC standard.
      </description>
      <properties>
        <property module="inequality">
          Gini coefficient in [0.0, 1.0] for any non-empty input.
          Lorenz curve is monotonically non-decreasing in both x and y.
          Lorenz curve starts at (0, 0) and ends at (1, 1).
        </property>
        <property module="change_entropy">
          Shannon entropy H >= 0 for any distribution.
          Normalized entropy in [0.0, 1.0] when files_modified >= 2.
          Entropy of uniform distribution = log2(N).
        </property>
        <property module="survival">
          S(t) is monotonically non-increasing.
          S(0) = 1.0 (all files alive at start).
          S(t) in [0.0, 1.0] for all t.
          at_risk >= events for every step.
        </property>
        <property module="focus">
          Developer focus in [0.0, 1.0] for any non-empty directory set.
          File diffusion in [0.0, 1.0] for any non-empty contributor set.
          Single-directory developer has focus = 1.0.
          Single-contributor file has diffusion = 0.0.
        </property>
        <property module="network">
          Network density in [0.0, 1.0] for V >= 2.
          Clustering coefficient in [0.0, 1.0] for each node.
          Total edges >= 0 and undirected (no double-counting).
          Connected components >= 1 for non-empty graph.
          Sum of component sizes = V.
        </property>
        <property module="circadian">
          All risk weights in (0.0, 2.0] (bounded above by max_hour_risk * weekend_mult).
          high_risk_percentage in [0.0, 100.0].
        </property>
        <property module="modularity">
          modularity_index in [0.0, 1.0].
          cross_module_ratio in [0.0, 1.0].
          modularity_index + cross_module_ratio approximately 1.0.
          total_intra_edges + total_cross_edges = total_edges.
        </property>
        <property module="congruence">
          congruence_score in [0.0, 1.0].
          actual_coordinations &lt;= required_coordinations (AC subset of CR implies this).
          coordination_gaps.len() &lt;= 20 (top-20 cap).
        </property>
      </properties>
    </phase>

    <phase id="6" name="Coverage Analysis and Reporting">
      <description>
        Measure line coverage with cargo-tarpaulin (MUST use --engine Llvm for accurate
        inline function tracing). Report before/after delta for all changes.
      </description>
      <steps>
        <step>Run: cargo tarpaulin -p rource-core --engine Llvm --out Stdout 2>&amp;1 | grep "coverage"</step>
        <step>Record per-file coverage for all insights modules</step>
        <step>Identify any files below 60% line coverage</step>
        <step>Add targeted tests to bring low-coverage files above 60%</step>
        <step>Report final coverage with exact percentages</step>
      </steps>
    </phase>

    <phase id="7" name="Documentation">
      <description>
        Create comprehensive documentation for the insights engine. Every metric
        must have its algorithm, complexity, research citation, and test strategy
        documented to PEER REVIEWED PUBLISHED ACADEMIC standard.
      </description>
      <deliverables>
        <deliverable>
          Update docs/performance/FUTURE_WORK.md with insights engine status.
          Include: test counts, mutation scores, coverage percentages, next steps.
        </deliverable>
        <deliverable>
          Ensure all 20 module doc comments include:
          - Research paper citation (Author, Year, Title)
          - Algorithm description with mathematical formulas
          - Computational complexity (accumulation + finalization)
          - Output field descriptions with units and ranges
        </deliverable>
        <deliverable>
          Update CLAUDE.md if any new learnings, patterns, or gotchas were discovered.
        </deliverable>
      </deliverables>
    </phase>

    <phase id="8" name="Final Verification and Commit">
      <description>
        Run the full verification suite and commit all changes with metrics.
      </description>
      <steps>
        <step>cargo test (all tests pass — report exact count)</step>
        <step>cargo clippy --all-targets --all-features -- -D warnings (zero warnings)</step>
        <step>cargo fmt --check (formatted)</step>
        <step>cargo tarpaulin -p rource-core --engine Llvm --out Stdout (coverage delta)</step>
        <step>Commit with: test count before/after, coverage before/after, mutation score if available</step>
        <step>Push to branch</step>
        <step>Update CLAUDE.md with session learnings</step>
      </steps>
    </phase>
  </task-specification>

  <testing-standards>
    <rule id="T1">Every test must have a // Kills: comment documenting the specific mutation it defeats</rule>
    <rule id="T2">Use exact value assertions: assert!((result - expected).abs() &lt; 1e-10) for f64</rule>
    <rule id="T3">Use assert_eq! for integer and boolean comparisons</rule>
    <rule id="T4">Test boundary values: exactly at threshold, one below, one above</rule>
    <rule id="T5">Test degenerate cases: empty input, single element, maximum input</rule>
    <rule id="T6">Never use format!()+push_str() for JSON — use write!() macro</rule>
    <rule id="T7">No serde dependency — all serialization is manual write!()</rule>
    <rule id="T8">Test names must be descriptive: test_[what]_[condition]_[expected]</rule>
    <rule id="T9">Each test must be independent — no shared mutable state between tests</rule>
    <rule id="T10">Helper functions that build test data must be deterministic and documented</rule>
  </testing-standards>

  <mutation-testing-standards>
    <rule id="M1">Every arithmetic operator (+, -, *, /) in a formula must have a test that fails if mutated</rule>
    <rule id="M2">Every comparison operator (&lt;, &lt;=, >, >=, ==, !=) at a threshold must have boundary tests</rule>
    <rule id="M3">Every logical operator (&amp;&amp;, ||) in a guard clause must have a test distinguishing the two</rule>
    <rule id="M4">Division guards (if x > 0) must have tests at x=0 and x=1 to kill > vs >= mutations</rule>
    <rule id="M5">Equivalent mutants must be PROVEN equivalent with mathematical argument, then excluded
      in .cargo/mutants.toml with the proof documented</rule>
    <rule id="M6">cargo-mutants exit codes: 0=success, 2=missed mutants, 124=timeout from wrapper</rule>
    <rule id="M7">Target mutation score: 80%+ for insights module</rule>
  </mutation-testing-standards>

  <architectural-constraints>
    <constraint id="A1">Single-pass O(N) accumulation — never iterate over commits more than once</constraint>
    <constraint id="A2">All computation at load time — zero per-frame cost within the 20us frame budget</constraint>
    <constraint id="A3">BULK_COMMIT_THRESHOLD = 50 — commits touching >50 files excluded from coupling</constraint>
    <constraint id="A4">No serde — all JSON output via manual write!() calls</constraint>
    <constraint id="A5">No external dependencies beyond what is already in Cargo.toml</constraint>
    <constraint id="A6">FxHashMap for internal hash maps (deterministic, fast)</constraint>
    <constraint id="A7">Output structs sorted deterministically (by score, name, or other defined order)</constraint>
    <constraint id="A8">Top-N limits on output vectors (top 50 hotspots, top 50 couplings, top 200 ownership, top 20 gaps)</constraint>
  </architectural-constraints>

  <research-citations>
    <citation module="hotspot">Nagappan, N., Ball, T., Zeller, A. (2005). Mining metrics to predict component failures. ICSE.</citation>
    <citation module="coupling">D'Ambros, M., Lanza, M., Robbes, R. (2009). On the relationship between change coupling and software defects. WCRE.</citation>
    <citation module="ownership">Bird, C., Nagappan, N., Murphy, B., Gall, H., Devanbu, P. (2011). Don't touch my code! ESEC/FSE.</citation>
    <citation module="ownership">Avelino, G., Passos, L., Hora, A., Valente, M. (2016). A novel approach for estimating truck factors. ICPC.</citation>
    <citation module="change_entropy">Hassan, A. E. (2009). Predicting faults using the complexity of code changes. ICSE.</citation>
    <citation module="change_bursts">Nagappan, N., Zeller, A., Zimmermann, T., Herzig, K., Murphy, B. (2010). Change bursts as defect predictors. ISSRE.</citation>
    <citation module="circadian">Eyolfson, J., Tan, L., Lam, P. (2011). Do time of day and developer experience affect commit bugginess? MSR.</citation>
    <citation module="inequality">Chelkowski, T., Gloor, P., Jemielniak, D. (2016). Inequality in open source software development. PLoS ONE.</citation>
    <citation module="focus">Posnett, D., D'Souza, R., Devanbu, P., Filkov, V. (2013). Dual ecological measures of focus in software development. ICSE.</citation>
    <citation module="survival">Cito, J., Cantrill, B. (2021). Measuring software development using Kaplan-Meier. ICSE-SEIP.</citation>
    <citation module="modularity">Silva, L., Valente, M., Maia, M. (2014). Modular structure of software systems. JSS.</citation>
    <citation module="congruence">Cataldo, M., Herbsleb, J., Carley, K. (2008). Socio-technical congruence: a framework. ESEM.</citation>
    <citation module="network">Begel, A., Nagappan, N., Poile, C., Laber, L. (2023). Developer collaboration networks. ESEC/FSE.</citation>
    <citation module="growth">Lehman, M. M. (1996). Laws of software evolution revisited. EWSPT.</citation>
    <citation module="work_type">Hindle, A., German, D. M., Holt, R. (2008). What do large commits tell us? MSR.</citation>
    <citation module="profiles">Mockus, A., Fielding, R. T., Herbsleb, J. D. (2002). Two case studies of open source software development. TOSEM.</citation>
    <citation module="knowledge">Rigby, P. C., Bird, C. (2013). Convergent contemporary software peer review practices. ESEC/FSE.</citation>
    <citation module="lifecycle">Godfrey, M. W., Tu, Q. (2000). Evolution in open source software: A case study. ICSM.</citation>
    <citation module="temporal">Nagappan, N., Murphy, B., Basili, V. (2008). The influence of organizational structure on software quality. ICSE.</citation>
    <citation module="cadence">Sliwerski, J., Zimmermann, T., Zeller, A. (2005). When do changes induce fixes? MSR.</citation>
  </research-citations>

  <anti-patterns>
    <anti-pattern>Do NOT add range-only assertions like assert!(x > 0.0) — these cannot kill arithmetic mutations</anti-pattern>
    <anti-pattern>Do NOT use format!() + push_str() for JSON output — use write!() macro</anti-pattern>
    <anti-pattern>Do NOT add serde as a dependency — manual serialization is a design decision</anti-pattern>
    <anti-pattern>Do NOT create helper abstractions for one-time test data — inline the setup</anti-pattern>
    <anti-pattern>Do NOT iterate over commits more than once — single-pass architecture is invariant</anti-pattern>
    <anti-pattern>Do NOT add tests without // Kills: comments — undocumented tests are unverifiable</anti-pattern>
    <anti-pattern>Do NOT assume a mutant is equivalent without mathematical proof</anti-pattern>
    <anti-pattern>Do NOT use cargo install in CI — always use cargo binstall for pre-built binaries</anti-pattern>
    <anti-pattern>Do NOT put EXIT_CODE=$? on a standalone line in GitHub Actions scripts</anti-pattern>
    <anti-pattern>Do NOT set CI time budgets above 20 minutes — platform enforces 30-min hard limit</anti-pattern>
    <anti-pattern>Do NOT place mutants.toml at workspace root — must be .cargo/mutants.toml</anti-pattern>
    <anti-pattern>Do NOT skip running clippy with --all-features — feature-gated modules will be missed</anti-pattern>
    <anti-pattern>Do NOT commit without recording test count and coverage before/after deltas</anti-pattern>
    <anti-pattern>Do NOT approximate performance claims — exact values with units or nothing</anti-pattern>
  </anti-patterns>

  <success-criteria>
    <criterion id="S1">All 352+ existing tests still pass (zero regressions)</criterion>
    <criterion id="S2">40-60 new mutation-killing tests added across 7 modules</criterion>
    <criterion id="S3">Total insights test count reaches ~400+ (352 baseline + new tests)</criterion>
    <criterion id="S4">Zero clippy warnings with --all-targets --all-features</criterion>
    <criterion id="S5">Code formatted (cargo fmt --check passes)</criterion>
    <criterion id="S6">Coverage does not decrease from baseline (measured with --engine Llvm)</criterion>
    <criterion id="S7">All new tests have // Kills: comments documenting mutation targets</criterion>
    <criterion id="S8">Any new equivalent mutants proven and documented in .cargo/mutants.toml</criterion>
    <criterion id="S9">CI mutation testing pipeline completes within 30 minutes</criterion>
    <criterion id="S10">Commit messages include exact before/after test counts and coverage</criterion>
    <criterion id="S11">Session learnings documented in CLAUDE.md or memory</criterion>
    <criterion id="S12">Each session remarkably better than the previous — measurable advancement</criterion>
  </success-criteria>

  <execution-protocol>
    <step order="1">Read this entire prompt. Internalize the standards. Understand the current state.</step>
    <step order="2">Read CLAUDE.md for the full project standards and non-negotiable rules.</step>
    <step order="3">Execute Phase 1: Verify clean baseline. Record all numbers.</step>
    <step order="4">Execute Phase 2: Add mutation-killing tests to 7 modules, one at a time.
      For each module: read the source, understand the algorithm, identify killable mutations,
      write tests with exact assertions, run cargo test to verify, move to next module.</step>
    <step order="5">Execute Phase 3: Push and validate CI. Fix any MISSED mutants.</step>
    <step order="6">Execute Phase 4: Integration tests if time permits.</step>
    <step order="7">Execute Phase 5: Property-based tests if time permits.</step>
    <step order="8">Execute Phase 6: Coverage analysis.</step>
    <step order="9">Execute Phase 7: Documentation updates.</step>
    <step order="10">Execute Phase 8: Final verification, commit, push.</step>
    <step order="11">Update CLAUDE.md with session learnings.</step>
    <step order="12">Phases 4-5 are stretch goals. Phases 1-3 and 6-8 are mandatory.</step>
  </execution-protocol>
</session-continuation>
